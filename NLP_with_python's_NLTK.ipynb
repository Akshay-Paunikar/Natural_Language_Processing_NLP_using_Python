{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural language processing (NLP) is a field that focuses on making natural human language usable by computer programs. NLTK, or Natural Language Toolkit, is a Python package that you can use for NLP.\n",
    "\n",
    "A lot of the data that you could be analyzing is unstructured data and contains human-readable text. Before you can analyze that data programmatically, you first need to preprocess it. Let's look at the kinds of text preprocessing tasks you can do with NLTK so that you'll be ready to apply them in future projects. You'll also see how to do some basic text analysis and create visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing\n",
    "\n",
    "By tokenizing, you can conveniently split up text by word or by sentence. This will allow you to work with smaller pieces of text that are still relatively coherent and meaningful even outside of the context of the rest of the text. It’s your first step in turning unstructured data into structured data, which is easier to analyze.\n",
    "\n",
    "When you’re analyzing text, you’ll be tokenizing by word and tokenizing by sentence. Here’s what both types of tokenization bring to the table:\n",
    " - <b>Tokenizing by word</b>: Words are like the atoms of natural language. They’re the smallest unit of meaning that still makes sense on its own. Tokenizing your text by word allows you to identify words that come up particularly often.\n",
    " - <b>Tokenizing by sentence</b>: When you tokenize by sentence, you can analyze how those words relate to one another and see more context. Are there a lot of negative words around the word “Python” because the hiring manager doesn’t like Python? Are there more terms from the domain of herpetology than the domain of software development, suggesting that you may be dealing with an entirely different kind of python than you were expecting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import word and sentence tokenize from nltk.tokenize\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sample data for demonstration\n",
    "sample_data = \"\"\"Today I am very happy to tell you that I have completed a project in NLP. With the use of NLP I extracted information on \n",
    "twitter sentiment analysis. I used that data to segment tweets into positive, negative and neutral tweets. In future I will use it to analyze \n",
    "comments from twitter account.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today I am very happy to tell you that I have completed a project in NLP.',\n",
       " 'With the use of NLP I extracted information on \\ntwitter sentiment analysis.',\n",
       " 'I used that data to segment tweets into positive, negative and neutral tweets.',\n",
       " 'In future I will use it to analyze \\ncomments from twitter account.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenize\n",
    "sent_tokenize(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today',\n",
       " 'I',\n",
       " 'am',\n",
       " 'very',\n",
       " 'happy',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'you',\n",
       " 'that',\n",
       " 'I',\n",
       " 'have',\n",
       " 'completed',\n",
       " 'a',\n",
       " 'project',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'I',\n",
       " 'extracted',\n",
       " 'information',\n",
       " 'on',\n",
       " 'twitter',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " '.',\n",
       " 'I',\n",
       " 'used',\n",
       " 'that',\n",
       " 'data',\n",
       " 'to',\n",
       " 'segment',\n",
       " 'tweets',\n",
       " 'into',\n",
       " 'positive',\n",
       " ',',\n",
       " 'negative',\n",
       " 'and',\n",
       " 'neutral',\n",
       " 'tweets',\n",
       " '.',\n",
       " 'In',\n",
       " 'future',\n",
       " 'I',\n",
       " 'will',\n",
       " 'use',\n",
       " 'it',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'comments',\n",
       " 'from',\n",
       " 'twitter',\n",
       " 'account',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenize\n",
    "word_tokenize(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
